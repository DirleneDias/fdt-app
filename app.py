# app_corrigido.py
# ---------------------------------------------------------
# Interface Streamlit para comparar dois arquivos (original vs alterado)
# e testar diferenÃ§as estatÃ­sticas nas competÃªncias, com interpretaÃ§Ã£o automÃ¡tica
# ---------------------------------------------------------

import streamlit as st
import pandas as pd
from thinking_limit_analysis import test_competencia

# --- ConfiguraÃ§Ã£o da pÃ¡gina ---
st.set_page_config(page_title="AnÃ¡lise de CompetÃªncias", page_icon="ğŸ“Š", layout="centered")

st.title("ğŸ“Š Comparador de CompetÃªncias")
st.write("Envie dois arquivos CSV â€” o **original** e o **com alteraÃ§Ã£o** â€” para comparar as competÃªncias.")

# --- Upload dos arquivos ---
col1, col2 = st.columns(2)

with col1:
    file_original = st.file_uploader("ğŸ“ Arquivo ORIGINAL (sem limitaÃ§Ã£o)", type=["csv"], key="original")

with col2:
    file_alterado = st.file_uploader("ğŸ“ Arquivo ALTERADO (com limitaÃ§Ã£o)", type=["csv"], key="alterado")

# --- Processamento apÃ³s upload ---
if file_original and file_alterado:
    df_original = pd.read_csv(file_original)
    df_alterado = pd.read_csv(file_alterado)

    st.success("âœ… Arquivos carregados com sucesso!")

    # Detecta colunas em comum
    colunas_comuns = list(set(df_original.columns) & set(df_alterado.columns))
    if not colunas_comuns:
        st.error("âŒ Nenhuma coluna em comum entre os arquivos. Verifique se ambos possuem o mesmo formato.")
        st.stop()

    # Detecta colunas de competÃªncias
    competencias = [col for col in colunas_comuns if col.startswith("C")]
    if not competencias:
        st.warning("âš ï¸ Nenhuma coluna de competÃªncia (ex: C2, C3) encontrada.")
        st.stop()

    competencia = st.selectbox("Escolha a competÃªncia para comparar:", competencias)

    if st.button("Rodar anÃ¡lise"):
        try:
            # --- Cria dataframe combinado ---
            df_comparado = pd.DataFrame()
            df_comparado[f"{competencia}_no_limit"] = df_original[competencia]
            df_comparado[f"{competencia}_with_limit"] = df_alterado[competencia]

            # --- Executa anÃ¡lise ---
            resultado = test_competencia(df_comparado, competencia)

            st.subheader(f"ğŸ“ˆ Resultados para {competencia}")

            # MÃ©tricas descritivas
            metricas = resultado["metricas"]
            st.markdown("### EstatÃ­sticas descritivas")
            st.json(metricas)

            # Resultado do teste estatÃ­stico
            teste = resultado["teste"]
            st.markdown("### Teste estatÃ­stico aplicado")
            st.write(f"**Teste:** {teste['teste']}")
            st.write(f"**p-valor:** {teste['p_value']:.5f}")
            st.write(f"**Normalidade (Shapiro):** p = {teste['shapiro_p']:.5f} â†’ {teste['normalidade']}")

            # --- InterpretaÃ§Ã£o automÃ¡tica ---
            st.markdown("### ğŸ§  InterpretaÃ§Ã£o dos Resultados")

            p_value = teste["p_value"]
            mean_a = metricas.get("mean_a")
            mean_b = metricas.get("mean_b")
            mean_diff = metricas.get("mean_diff")
            cohen_d = metricas.get("cohen_d")

            if p_value < 0.05:
                direcao = "maior" if mean_a > mean_b else "menor"
                intensidade = (
                    "pequeno" if cohen_d < 0.3 else
                    "moderado" if cohen_d < 0.6 else
                    "grande"
                )

                st.markdown(
                    f'''
                    <div style="
                        background-color:#d1f7d6;
                        border-left:6px solid #2ecc71;
                        padding:15px;
                        border-radius:10px;
                        margin-top:10px;
                    ">
                    <h4>âœ… Teste estatisticamente <b>relevante</b> (p = {p_value:.5f})</h4>
                    <ul>
                        <li>A mÃ©dia da condiÃ§Ã£o <b>A</b> ({mean_a:.2f}) Ã© <b>{direcao}</b> que a da condiÃ§Ã£o <b>B</b> ({mean_b:.2f}).</li>
                        <li>DiferenÃ§a mÃ©dia: <b>{mean_diff:.2f}</b> pontos.</li>
                        <li>O teste indica que essa diferenÃ§a <b>nÃ£o ocorreu por acaso</b>.</li>
                        <li><b>Tamanho de efeito (Cohenâ€™s d = {cohen_d:.2f})</b>: {intensidade} ({'relevante' if cohen_d >= 0.3 else 'sutil'}).</li>
                    </ul>
                    </div>
                    ''',
                    unsafe_allow_html=True
                )
            else:
                intensidade = (
                    "muito pequeno" if cohen_d < 0.2 else
                    "pequeno" if cohen_d < 0.3 else
                    "moderado"
                )

                st.markdown(
                    f'''
                    <div style="
                        background-color:#ffe6e6;
                        border-left:6px solid #e74c3c;
                        padding:15px;
                        border-radius:10px;
                        margin-top:10px;
                    ">
                    <h4>âŒ Teste <b>nÃ£o relevante</b> (p = {p_value:.5f})</h4>
                    <ul>
                        <li>As mÃ©dias sÃ£o semelhantes (A = {mean_a:.2f}, B = {mean_b:.2f}).</li>
                        <li>DiferenÃ§a observada ({mean_diff:.2f}) pode ter ocorrido ao acaso.</li>
                        <li><b>Tamanho de efeito (Cohenâ€™s d = {cohen_d:.2f})</b>: {intensidade}.</li>
                    </ul>
                    </div>
                    ''',
                    unsafe_allow_html=True
                )

            st.caption("ğŸ’¬ InterpretaÃ§Ã£o gerada automaticamente com base nas estatÃ­sticas calculadas.")

        except Exception as e:
            st.error(f"Erro ao processar: {e}")

else:
    st.info("ğŸ“‚ Por favor, envie os dois arquivos CSV para comeÃ§ar.")
